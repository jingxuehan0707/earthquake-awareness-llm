{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ae1adbf",
   "metadata": {},
   "source": [
    "# Earthquake Awareness With LLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524688b2",
   "metadata": {},
   "source": [
    "This Jupyter Notebook demonstrates a project built using the [ReAct Framework](https://arxiv.org/abs/2210.03629) in combination with the OpenAI API, ArcGIS World Geocoding Service, and USGS real-time earthquake feeds. \n",
    "\n",
    "By integrating GPT-4 with external APIs, this project bridges the fields of Large Language Models (LLMs), Geographic Information Systems (GIS), and natural hazard risk analysis. It showcases the potential for interdisciplinary research and real-world applications, unlocking new opportunities for impactful solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98b77cde",
   "metadata": {},
   "source": [
    "## 1. Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2549d434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Langchain imports\n",
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.prompts import BaseChatPromptTemplate\n",
    "from langchain.schema import AgentAction, AgentFinish, HumanMessage\n",
    "from langchain import LLMChain\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "# Standard library imports\n",
    "from typing import List, Union\n",
    "import requests\n",
    "import json\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e504d3f",
   "metadata": {},
   "source": [
    "## 2. Tool definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7aff2c",
   "metadata": {},
   "source": [
    "This section defines two tools that leverage external APIs to provide geospatial and earthquake-related functionalities:\n",
    "\n",
    "- **ArcGIS World Geocoding Service**: Converts a place name into geographic coordinates (latitude and longitude). This tool enables seamless geocoding for GIS workflows.\n",
    "- **USGS Earthquake Real-Time Feeds**: Retrieves the count of earthquakes within a specified time window and geographic region. Parameters include location, radius, and minimum magnitude, facilitating advanced earthquake data analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5c915ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Tool: Geocode using ArcGIS REST API ---\n",
    "def geocode(placename):\n",
    "    url = \"https://geocode.arcgis.com/arcgis/rest/services/World/GeocodeServer/findAddressCandidates\"\n",
    "    params = {\n",
    "        \"SingleLine\": placename,\n",
    "        \"f\": \"json\"\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    candidates = response.json().get(\"candidates\", [])\n",
    "    if candidates:\n",
    "        location = candidates[0][\"location\"]\n",
    "        return location[\"y\"], location[\"x\"]  # latitude, longitude\n",
    "    else:\n",
    "        raise ValueError(f\"Could not geocode location: {placename}\")\n",
    "\n",
    "# --- Tool: Earthquake Count ---\n",
    "def get_earthquake_count(starttime, endtime, latitude, longitude, maxradius, minmagnitude):\n",
    "    url = \"https://earthquake.usgs.gov/fdsnws/event/1/count\"\n",
    "    params = {\n",
    "        \"starttime\": starttime,\n",
    "        \"endtime\": endtime,\n",
    "        \"latitude\": latitude,\n",
    "        \"longitude\": longitude,\n",
    "        \"maxradius\": maxradius,\n",
    "        \"minmagnitude\": minmagnitude,\n",
    "        \"format\": \"geojson\"\n",
    "    }\n",
    "    response = requests.get(url, params=params)\n",
    "    return response.json().get(\"count\", 0)\n",
    "    return response.json().get(\"count\", 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd1b483",
   "metadata": {},
   "source": [
    "## 3. ReAct Implementation with Langchain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dd891a7",
   "metadata": {},
   "source": [
    "This section demonstrates a ReAct (Reasoning + Acting) implementation using the Langchain framework. The ReAct framework enables the integration of reasoning and action-taking capabilities, allowing the agent to interact with tools, process intermediate steps, and arrive at a final answer in a structured manner.\n",
    "\n",
    "The Langchain framework provides a robust and modular approach to building applications powered by Large Language Models (LLMs). By leveraging Langchain, developers can seamlessly integrate external tools, define custom prompts, and implement advanced workflows like ReAct. This enhances the agent's ability to perform complex tasks, such as geospatial analysis and earthquake data retrieval, while maintaining flexibility and scalability in the application design."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "48edd0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- LangChain Tool Wrappers ---\n",
    "geocode_tool = Tool(\n",
    "    name=\"Geocode\",\n",
    "    func=lambda place: str(geocode(place)),\n",
    "    description=\"Returns (latitude, longitude) for a place using ArcGIS REST API. Input should be a place name.\"\n",
    ")\n",
    "\n",
    "earthquake_tool = Tool(\n",
    "    name=\"EarthquakeCount\",\n",
    "    func=lambda args: str(\n",
    "        get_earthquake_count(\n",
    "            starttime=json.loads(args).get(\"starttime\"),\n",
    "            endtime=json.loads(args).get(\"endtime\"),\n",
    "            latitude=json.loads(args).get(\"latitude\"),\n",
    "            longitude=json.loads(args).get(\"longitude\"),\n",
    "            maxradius=json.loads(args).get(\"maxradius\", 1),\n",
    "            minmagnitude=json.loads(args).get(\"minmagnitude\", 1)\n",
    "        )\n",
    "    ),\n",
    "    description=\"Returns number of earthquakes in a time window and region. Input should be a dict with keys: starttime, endtime, latitude, longitude, maxradius (in degree), minmagnitude.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "61473e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Custom Prompt Template ---\n",
    "class CustomPromptTemplate(BaseChatPromptTemplate):\n",
    "    # The template to use\n",
    "    template: str\n",
    "    # The list of tools available\n",
    "    tools: List[Tool]\n",
    "    \n",
    "    def format_messages(self, **kwargs) -> str:\n",
    "        # Get the intermediate steps (AgentAction, Observation tuples)\n",
    "        # Format them in a particular way\n",
    "        intermediate_steps = kwargs.pop(\"intermediate_steps\")\n",
    "        thoughts = \"\"\n",
    "        for action, observation in intermediate_steps:\n",
    "            thoughts += action.log\n",
    "            thoughts += f\"\\nObservation: {observation}\\nThought: \"\n",
    "            \n",
    "        # Set the agent_scratchpad variable to that value\n",
    "        kwargs[\"agent_scratchpad\"] = thoughts\n",
    "        \n",
    "        # Create a tools variable from the list of tools provided\n",
    "        kwargs[\"tools\"] = \"\\n\".join([f\"{tool.name}: {tool.description}\" for tool in self.tools])\n",
    "        \n",
    "        # Create a list of tool names for the tools provided\n",
    "        kwargs[\"tool_names\"] = \", \".join([tool.name for tool in self.tools])\n",
    "        formatted = self.template.format(**kwargs)\n",
    "        return [HumanMessage(content=formatted)]\n",
    "    \n",
    "# --- Custom Output Parser ---\n",
    "class CustomOutputParser(AgentOutputParser):\n",
    "    \n",
    "    def parse(self, llm_output: str) -> Union[AgentAction, AgentFinish]:\n",
    "        \n",
    "        # Check if agent should finish\n",
    "        if \"Final Answer:\" in llm_output:\n",
    "            return AgentFinish(\n",
    "                # Return values is generally always a dictionary with a single `output` key\n",
    "                # It is not recommended to try anything else at the moment :)\n",
    "                return_values={\"output\": llm_output.split(\"Final Answer:\")[-1].strip()},\n",
    "                log=llm_output,\n",
    "            )\n",
    "        \n",
    "        # Parse out the action and action input\n",
    "        regex = r\"Action: (.*?)[\\n]*Action Input:[\\s]*(.*)\"\n",
    "        match = re.search(regex, llm_output, re.DOTALL)\n",
    "        \n",
    "        # If it can't parse the output it raises an error\n",
    "        # You can add your own logic here to handle errors in a different way i.e. pass to a human, give a canned response\n",
    "        if not match:\n",
    "            raise ValueError(f\"Could not parse LLM output: `{llm_output}`\")\n",
    "        action = match.group(1).strip()\n",
    "        action_input = match.group(2)\n",
    "        \n",
    "        # Return the action and action input\n",
    "        return AgentAction(tool=action, tool_input=action_input.strip(\" \").strip('\"'), log=llm_output)\n",
    "\n",
    "# --- Prompt Template Setup ---\n",
    "tools = [geocode_tool, earthquake_tool]\n",
    "template = \"\"\"\n",
    "You are a GIS professional with expertise in natural hazards and disaster risk analysis.\n",
    "Answer the following question using available tools.\n",
    "You have access to the following tools:\n",
    "\n",
    "{tools}\n",
    "\n",
    "Use the following format:\n",
    "Question: the input question you must answer\n",
    "Thought: you should always think about what to do\n",
    "Action: the action to take, should be one of [{tool_names}]\n",
    "Action Input: the input to the action\n",
    "Observation: the result of the action\n",
    "... (this Thought/Action/Action Input/Observation can repeat N times)\n",
    "Thought: I now know the final answer\n",
    "Final Answer: the final answer to the original input question\n",
    "\n",
    "Begin!\n",
    "\n",
    "Question: {input}\n",
    "{agent_scratchpad}\"\"\"\n",
    "\n",
    "prompt = CustomPromptTemplate(\n",
    "    template=template,\n",
    "    tools=tools,\n",
    "    input_variables=[\"input\", \"intermediate_steps\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ab11e91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6g/xqgvnv4s1h95kfz0bd14h3_h0000gn/T/ipykernel_16606/1619865486.py:2: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm = ChatOpenAI(model='gpt-4.1', temperature=0)\n",
      "/var/folders/6g/xqgvnv4s1h95kfz0bd14h3_h0000gn/T/ipykernel_16606/1619865486.py:5: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
      "/var/folders/6g/xqgvnv4s1h95kfz0bd14h3_h0000gn/T/ipykernel_16606/1619865486.py:14: LangChainDeprecationWarning: LangChain agents will continue to be supported, but it is recommended for new use cases to be built with LangGraph. LangGraph offers a more flexible and full-featured framework for building agents, including support for tool-calling, persistence of state, and human-in-the-loop workflows. For details, refer to the `LangGraph documentation <https://langchain-ai.github.io/langgraph/>`_ as well as guides for `Migrating from AgentExecutor <https://python.langchain.com/docs/how_to/migrate_agent/>`_ and LangGraph's `Pre-built ReAct agent <https://langchain-ai.github.io/langgraph/how-tos/create-react-agent/>`_.\n",
      "  agent = LLMSingleActionAgent(\n"
     ]
    }
   ],
   "source": [
    "# Initiate our LLM (Language Model) - using 'gpt-4.1' with a temperature of 0 for deterministic responses\n",
    "llm = ChatOpenAI(model='gpt-4.1', temperature=0)\n",
    "\n",
    "# Create an LLM chain that combines the LLM and the custom prompt template\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "\n",
    "# Extract tool names from the list of tools for use in the agent\n",
    "tool_names = [tool.name for tool in tools]\n",
    "\n",
    "# Create a custom output parser to handle the LLM's output\n",
    "output_parser = CustomOutputParser()\n",
    "\n",
    "# Create an agent that uses the LLM chain, output parser, and tools\n",
    "agent = LLMSingleActionAgent(\n",
    "    llm_chain=llm_chain,  # The LLM chain to process input and generate output\n",
    "    output_parser=output_parser,  # The parser to interpret the LLM's output\n",
    "    stop=[\"\\nObservation:\"],  # Stop sequence to end processing after tool output\n",
    "    allowed_tools=tool_names  # List of tools the agent is allowed to use\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "546dca5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an agent executor that combines the agent with the tools\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9706dcbd",
   "metadata": {},
   "source": [
    "## 4. Ask LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1d06550b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/6g/xqgvnv4s1h95kfz0bd14h3_h0000gn/T/ipykernel_16606/2960268015.py:2: LangChainDeprecationWarning: The method `Chain.run` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  agent_executor.run(\"Is there any significant earthquake in Riverside, CA in Jan 2024?\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mThought: First, I need to get the coordinates (latitude and longitude) for Riverside, CA. Then, I will check for earthquakes in January 2024 near that location with a significant magnitude (let's use minmagnitude 4.0 as a threshold).\n",
      "Action: Geocode\n",
      "Action Input: Riverside, CA\u001b[0m\n",
      "\n",
      "Observation:\u001b[36;1m\u001b[1;3m(33.980534, -117.377025)\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mNow that I have the coordinates for Riverside, CA, I will search for earthquakes with a magnitude of at least 4.0 within a reasonable radius (let's use 50 km, which is approximately 0.45 degrees) during January 2024.\n",
      "Action: EarthquakeCount\n",
      "Action Input: {\"starttime\": \"2024-01-01\", \"endtime\": \"2024-01-31\", \"latitude\": 33.980534, \"longitude\": -117.377025, \"maxradius\": 0.45, \"minmagnitude\": 4.0}\u001b[0m\n",
      "\n",
      "Observation:\u001b[33;1m\u001b[1;3m2\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
      "Final Answer: Yes, there were 2 significant earthquakes (magnitude 4.0 or higher) in or near Riverside, CA during January 2024.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Yes, there were 2 significant earthquakes (magnitude 4.0 or higher) in or near Riverside, CA during January 2024.'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the agent executor with a sample question\n",
    "agent_executor.run(\"Is there any significant earthquake in Riverside, CA in Jan 2024?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4eeb3a3",
   "metadata": {},
   "source": [
    "# Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae761ccb",
   "metadata": {},
   "source": [
    "Jarvis, C., & Palermo, J. (2023, June 13). How to call functions with Chat models. OpenAI. https://cookbook.openai.com/examples/how_to_call_functions_with_chat_models\n",
    "\n",
    "Jarvis, C. (2023, May 2). How to build a tool-using agent with LangChain. OpenAI. https://cookbook.openai.com/examples/how_to_build_a_tool-using_agent_with_langchain\n",
    "\n",
    "Noun, T. (2023, March 14). Creating a ReAct agent from scratch using OpenAI: No frameworks required. Medium. https://medium.com/@original2547/creating-a-react-agent-from-scratch-using-openai-no-frameworks-required-111910f887f8\n",
    "\n",
    "Yao, S., Zhao, J., Zhang, D., Ktitarev, A., Radev, D., & Liu, D. (2022). ReAct: Synergizing reasoning and acting in language models (arXiv preprint arXiv:2210.03629). https://arxiv.org/abs/2210.03629"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "geo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
